apiVersion: v1
kind: Pod
metadata:
  name: gpu-benchmark
  labels:
    app: gpu-benchmark
spec:
  restartPolicy: Never
  containers:
  - name: benchmark
    image: nvidia/cuda:13.1.0-devel-ubuntu22.04
    command: ["/bin/bash", "-c"]
    args:
      - |
        set -e
        echo "=== GPU Benchmark in Kubernetes ==="
        echo ""

        # Show GPU info
        nvidia-smi
        echo ""

        # Compile benchmark
        cd /workspace
        gcc -o gpu_benchmark simple_gpu_benchmark.c \
          -I/usr/local/cuda/include \
          -L/usr/local/cuda/lib64 \
          -lcuda

        echo ""
        echo "=== Running Baseline Benchmark ==="
        ./gpu_benchmark

        echo ""
        echo "=== Benchmark Complete ==="
        echo "Results saved. Pod will remain running for inspection."

        # Keep pod alive for log inspection
        sleep infinity

    resources:
      limits:
        nvidia.com/gpu: 1

    volumeMounts:
    - name: benchmark-code
      mountPath: /workspace

  volumes:
  - name: benchmark-code
    hostPath:
      path: /mnt/data/mlperf-benchmark/scripts
      type: Directory
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: benchmark-results
data:
  README.md: |
    # GPU Benchmark Results in Kubernetes

    View benchmark logs:
      kubectl logs gpu-benchmark

    Copy results out:
      kubectl logs gpu-benchmark > k8s-baseline-results.txt

    Delete pod:
      kubectl delete pod gpu-benchmark
